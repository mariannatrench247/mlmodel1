import tensorflow as tf 
#load dataset 

mnist = tf.keras.datasets.mnist

(x_train, y_train), (x_test, y_test) = mnist.load_data()
x_train, x_test = x_train / 255.0, x_test / 255.0

#build tf.keras.Sequential model: 
#sequential stacks layers - each layer (has one input tensor/one output tensor)
# Flatten, Dense, Dropout Layers 
model = tf.keras.models.Sequential([
    tf.keras.layers.Flatten(input_shape=(28, 28)),
    tf.keras.layers.Dense(128, activation='relu'),
    tf.keras.layers.Dropout(0.2),
    tf.keras.layers.Dense(10)
    ])

#returns vector of logits/log-odds scores, one for each class
predictions = model(x_train[:1]).numpy()
predictions

#converts logits to probabilities/class
tf.nn.softmax(predictions).numpy()

#loss function defined for training. loss function takes vector of ground truth values
#and vector of logits and returns scalar loss for each example
#loss = negative log probability of the true class 
# loss is zero if model is sure of the correct class

loss_fn = tf.keras.losses.SparseCategoricalCrossentropy(from_logits=True)
loss_fn(y_train[:1], predictions).numpy()

#before training begins: set optimizer class to adam. loss to loss_fn function and 
#specify metric to be evaluated for model by setting metrics parameter to accuracy

model.compile(optimizer='adam', 
              loss=loss_fn,
              metrics=['accuracy'])


#TRAIN AND EVALUATE MODEL 
model.fit(x_train, y_train, epochs=5)

#Model.evaluate checks model's performance, on validation or test set 
model.evaluate(x_test,  y_test, verbose=2)

#image classifier now trained. 

#model to return probability, wrap trained model and attach softmax to it

probability_model = tf.keras.Sequential([
    model, 
    tf.keras.layers.Softmax()
]) 

probability_model(x_test[:5])

#Model complete. Prebuilt Dataset with Keras API

#RESULTS
Epoch 1/5
1875/1875 [==============================] - 8s 4ms/step - loss: 0.2965 - accuracy: 0.9149
Epoch 2/5
1875/1875 [==============================] - 9s 5ms/step - loss: 0.1425 - accuracy: 0.9576
Epoch 3/5
1875/1875 [==============================] - 11s 6ms/step - loss: 0.1074 - accuracy: 0.9676
Epoch 4/5
1875/1875 [==============================] - 9s 5ms/step - loss: 0.0886 - accuracy: 0.9730
Epoch 5/5
1875/1875 [==============================] - 7s 4ms/step - loss: 0.0768 - accuracy: 0.9766
313/313 - 1s - loss: 0.0787 - accuracy: 0.9762 - 987ms/epoch - 3ms/step
<tf.Tensor: shape=(5, 10), dtype=float32, numpy=
array([[1.1697410e-06, 4.4607361e-08, 1.4822867e-05, 1.2366305e-04,
        1.2447257e-10, 5.4967586e-07, 1.7432385e-11, 9.9981159e-01,
        1.2165767e-05, 3.5971218e-05],
       [1.0633990e-11, 4.5070014e-05, 9.9995446e-01, 6.6944033e-08,
        2.1294390e-17, 2.6327502e-08, 6.1752918e-09, 4.2271683e-15,
        3.0969932e-07, 7.2576521e-14],
       [6.1847189e-08, 9.9876785e-01, 1.4637737e-04, 3.6107499e-06,
        3.8312301e-05, 4.1033522e-06, 1.5565599e-06, 9.2447281e-04,
        1.1098303e-04, 2.6872845e-06],
       [9.9835962e-01, 9.3185741e-07, 3.7847497e-04, 5.5107630e-05,
        2.4226001e-06, 2.4595283e-04, 6.9410773e-04, 1.2469917e-04,
        4.1724834e-07, 1.3830440e-04],
       [9.9009344e-07, 1.4705341e-07, 4.8215652e-06, 1.0146981e-07,
        9.9831116e-01, 2.1562148e-07, 1.2203976e-05, 2.1113294e-04,
        9.9900199e-06, 1.4493009e-03]], dtype=float32)>
import tensorflow as tf 
